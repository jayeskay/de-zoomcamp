# ETL

## Summary

| Dataset     | Year        | Duration    |
| ----------- | ----------- | ----------- |
| FHV         | 2019        | ~14m, 20s   |
| GREEN       | 2020        | ~5m, 25s    |
| YELLOW      | 2020        | ~45m        |

## Process

### Generation

Data is supplied to the New York City Taxi & Limousine Commission ("TLC"). Specifically, per [website](https://www.nyc.gov/site/tlc/about/data-and-research.page),

> Policy researchers at TLC use data generated by our licensees to observe changing trends in the industry and inform decisions made by our agency and the City.

### Source

Base URL: https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page

Data is housed on CloudFront. Hypertext reference attribute ("href") links are ripped from the above page to pull in correct URL and corresponding subset of data and respective year.

### Ingestion

Process uses `stream_download_parquet(url, dtypes)` to ingest data, pulling desired subset of files. 

### Transformation

`dtypes` in the above referenced function are defined as follows:

#### FHV

```python
dtypes = {
    'dispatching_base_num':     str,
    'pickup_datetime':          str,
    'dropOff_datetime':         str,
    'PUlocationID':             pd.Int64Dtype(),
    'DOlocationID':             pd.Int64Dtype(),
    'SR_Flag':                  pd.Int64Dtype(),
    'Affiliated_base_number':   str
}
```

#### Green

```python
taxi_data_dtypes = {
    'VendorID': pd.Int64Dtype(),
    'lpep_pickup_datetime': 'datetime64[ns]',
    'lpep_dropoff_datetime': 'datetime64[ns]',
    'store_and_fwd_flag': str,
    'RatecodeID': pd.Int64Dtype(),
    'PULocationID': pd.Int64Dtype(),
    'DOLocationID': pd.Int64Dtype(),
    'passenger_count': pd.Int64Dtype(),
    'trip_distance': float,
    'fare_amount': float,
    'extra': float,
    'mta_tax': float,
    'tip_amount': float,
    'tolls_amount': float,
    'improvement_surcharge': float,
    'total_amount': float,
    'payment_type': pd.Int64Dtype(),
    'congestion_surcharge': float
}
```

#### Yellow

```python
taxi_data_dtypes = {
    'VendorID': pd.Int64Dtype(),
    'tpep_pickup_datetime': 'datetime64[ns]',
    'tpep_dropoff_datetime': 'datetime64[ns]',
    'store_and_fwd_flag': str,
    'RatecodeID': pd.Int64Dtype(),
    'PULocationID': pd.Int64Dtype(),
    'DOLocationID': pd.Int64Dtype(),
    'passenger_count': pd.Int64Dtype(),
    'trip_distance': float,
    'fare_amount': float,
    'extra': float,
    'mta_tax': float,
    'tip_amount': float,
    'tolls_amount': float,
    'improvement_surcharge': float,
    'total_amount': float,
    'payment_type': pd.Int64Dtype(),
    'congestion_surcharge': float
}
```

### Destination

A function is used to load batches to S3: `stream_upload_parquet(df: pd.DataFrame, bucket: str, object_key: str)`.

`df` is the subset of data to be loaded as a batch.

The remaining two parameters are defined as follows, corresponding to `bucket` and *part* of `object_key`, respectively:

> [!WARNING]  
> `YYYY` in the below is a placeholder for dataset year--it is specified in respective scripts.

#### FHV

```python
BUCKET = 'dez2024-dez-dlt'
PREFIX = 'ny_taxi/fhv/YYYY'
```

#### Green

```python
BUCKET = 'dez2024-dez-dlt'
PREFIX = 'ny_taxi/green/YYYY'
```

#### Yellow

```python
BUCKET = 'dez2024-dez-dlt'
PREFIX = 'ny_taxi/yellow/YYYY'
```

The remainder of `object_key` is set as shown, where `d` is an individual date set by `for` loop:

```python
object_key=f"{PREFIX}/{d.strftime('%Y%m%d')}.parquet.gz"
```
